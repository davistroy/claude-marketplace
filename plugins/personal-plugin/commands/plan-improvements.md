---
description: Analyze codebase and generate prioritized improvement recommendations with phased implementation plan
---

# Plan Improvements Command

Perform a comprehensive analysis of the current codebase to identify improvement opportunities, then generate detailed recommendations and a phased implementation plan.

## Input Validation

Before proceeding, verify:
- This is a code project with meaningful source files (not empty or purely documentation)
- The repository structure is readable and accessible
- There is sufficient existing code to analyze for improvements

For trivial projects or fresh repositories, ask the user if they want a full improvement plan or just architectural guidance.

## Instructions

### Phase 1: Deep Codebase Analysis (Ultrathink)

Thoroughly analyze the entire codebase with extended thinking enabled. Focus on:

#### Usability Assessment
- How intuitive is the current workflow?
- Are there friction points in common operations?
- Is the documentation clear and complete?
- Are error messages helpful and actionable?
- Is configuration straightforward?

#### Output Quality Assessment
- Does the output meet professional standards?
- Are there consistency issues in generated content?
- Could templates or patterns improve output quality?
- Are there edge cases that produce poor results?
- What validation or quality checks are missing?

#### Architecture & Design
- Is the code organized logically?
- Are there opportunities for better abstraction?
- Are patterns applied consistently?
- Are there scalability concerns?
- Is the design extensible for future needs?

#### Developer Experience
- How easy is it to add new features?
- Is the code self-documenting?
- Are conventions clear and enforced?
- Are there testing gaps?

#### Missing Capabilities
- What features would users expect but are missing?
- What integrations would add value?
- What automation opportunities exist?

### Phase 2: Generate RECOMMENDATIONS.md

Create a comprehensive recommendations document with this structure:

```markdown
# Improvement Recommendations

**Generated:** [YYYY-MM-DD HH:MM:SS]
**Analyzed Project:** [project name/path]

---

## Executive Summary

[2-3 paragraph overview of key findings and highest-impact recommendations]

---

## Recommendation Categories

### Category 1: Usability Improvements

#### U1. [Recommendation Title]

**Priority:** Critical | High | Medium | Low
**Effort:** XS | S | M | L | XL
**Impact:** [Description of benefit]

**Current State:**
[What exists now and why it's problematic]

**Recommendation:**
[Specific, actionable improvement]

**Implementation Notes:**
[Technical considerations, dependencies, risks]

---

### Category 2: Output Quality Enhancements

#### Q1. [Recommendation Title]
...

---

### Category 3: Architectural Improvements

#### A1. [Recommendation Title]
...

---

### Category 4: Developer Experience

#### D1. [Recommendation Title]
...

---

### Category 5: New Capabilities

#### N1. [Recommendation Title]
...

---

## Quick Wins

[List of low-effort, high-impact items that can be done immediately]

---

## Strategic Initiatives

[List of larger changes that require planning]

---

## Not Recommended

[Items considered but rejected, with rationale - prevents revisiting]

---

*Recommendations generated by Claude on [YYYY-MM-DD HH:MM:SS]*
```

### Phase 3: Generate IMPLEMENTATION_PLAN.md

#### Append vs Overwrite Logic

**Before writing, check if IMPLEMENTATION_PLAN.md already exists.**

- **If the file does NOT exist:** Create it fresh with the full structure below.
- **If the file DOES exist:**
  1. Read the existing file
  2. Preserve the existing header (everything up to and including the `---` after Plan Overview / Phase Summary Table)
  3. Identify the highest existing phase number (e.g., if Phase 4 is the last, new phases start at Phase 5)
  4. Renumber all new phases to continue from the highest existing phase
  5. Renumber all new work items accordingly (e.g., 5.1, 5.2, 6.1...)
  6. Append the new phases after the last existing phase section
  7. Update the Phase Summary Table to include both old and new phases
  8. Update the total phase count, estimated total effort, and any metadata in the header
  9. Append new entries to Parallel Work Opportunities, Risk Mitigation, Success Metrics tables
  10. Add a separator comment before the new content: `<!-- Appended on [YYYY-MM-DD HH:MM:SS] from /plan-improvements -->`

**Tell the user what happened:**
```text
Existing IMPLEMENTATION_PLAN.md found with [N] phases.
Appending [M] new phases (Phase [N+1] through Phase [N+M]).
```

Transform recommendations into an actionable, phased implementation plan:

```markdown
# Implementation Plan

**Generated:** [YYYY-MM-DD HH:MM:SS]
**Based On:** RECOMMENDATIONS.md
**Total Phases:** [N]
**Estimated Total Effort:** ~[X] LOC across [Y] files

---

## Executive Summary

[2-3 paragraph overview of what will be changed, key improvement themes, and implementation strategy]

---

## Plan Overview

[Summary of the implementation strategy and phasing rationale]

### Phase Summary Table

| Phase | Focus Area | Key Deliverables | Est. Complexity | Dependencies |
|-------|------------|------------------|-----------------|--------------|
| 1 | [Area] | [Deliverables] | M (~N files, ~N LOC) | None |
| 2 | [Area] | [Deliverables] | M (~N files, ~N LOC) | Phase 1 |
| ... | ... | ... | ... | ... |

---

## Phase 1: [Phase Title]

**Estimated Complexity:** [S/M/L] (~N files, ~N LOC)
**Dependencies:** [None | List of phases]
**Parallelizable:** [Yes/No - can work items run concurrently]

### Goals
- [Goal 1]
- [Goal 2]

### Work Items

#### 1.1 [Task Title]
**Recommendation Ref:** [U1, A2, etc.]
**Files Affected:**
- `path/to/file1.ext` (create)
- `path/to/file2.ext` (modify)

**Description:**
[Detailed task description]

**Tasks:**
1. [ ] [Specific task 1 with enough detail to execute]
2. [ ] [Specific task 2 with enough detail to execute]
3. [ ] [Specific task 3 with enough detail to execute]

**Acceptance Criteria:**
- [ ] [Criterion 1]
- [ ] [Criterion 2]

**Notes:**
[Any additional context, gotchas, or implementation hints]

---

#### 1.2 [Task Title]
...

### Phase 1 Testing Requirements

- [ ] [Specific test requirement 1]
- [ ] [Specific test requirement 2]
- [ ] All new code has >80% test coverage
- [ ] Integration tests pass

### Phase 1 Completion Checklist

- [ ] All work items complete
- [ ] All tests passing
- [ ] Documentation updated
- [ ] No regressions introduced
- [ ] Code reviewed (if applicable)

---

## Phase 2: [Phase Title]
...

---

## Parallel Work Opportunities

[Identify which phases or work items can be executed concurrently]

| Work Item | Can Run With | Notes |
|-----------|--------------|-------|
| Phase 1.1 | Phase 1.2 | [Why these are independent] |
| ... | ... | ... |

---

## Risk Mitigation

| Risk | Likelihood | Impact | Mitigation Strategy |
|------|------------|--------|---------------------|
| [Risk 1] | Low/Med/High | Low/Med/High | [Strategy] |
| [Risk 2] | Low/Med/High | Low/Med/High | [Strategy] |

---

## Success Metrics

[How to measure overall success of the implementation]

- [ ] All phases completed
- [ ] All acceptance criteria met
- [ ] [Impact metric 1 from recommendations]
- [ ] [Impact metric 2 from recommendations]

---

## Appendix: Recommendation Traceability

| Recommendation | Source | Phase | Work Item |
|----------------|--------|-------|-----------|
| [U1] | RECOMMENDATIONS.md | 1 | 1.1 |
| [A2] | RECOMMENDATIONS.md | 1 | 1.2 |
| ... | ... | ... | ... |

---

*Implementation plan generated by Claude on [YYYY-MM-DD HH:MM:SS]*
*Source: /plan-improvements command*
```

#### Work Item Construction Guidelines

For each work item, generate all six fields in this order:

1. **Recommendation Ref** — the recommendation ID(s) from RECOMMENDATIONS.md (e.g., U1, A2)
2. **Files Affected** — list with `(create)` or `(modify)` annotations per file
3. **Description** — detailed explanation of the change and why it matters
4. **Tasks** — numbered checkbox list of specific, actionable sub-steps that an implementer can execute sequentially. Each task should be concrete enough to complete without further decomposition. Include testing and documentation tasks.
5. **Acceptance Criteria** — measurable conditions that verify the work item is done
6. **Notes** — optional context, gotchas, dependencies, or implementation hints. Omit if there is nothing noteworthy to add.

### Phase Sizing Guidelines

Each phase should be completable by a single subagent session. Use these concrete heuristics:

**Per-phase guidelines:**
- Read 5-8 files, modify 3-5 files, change ~500 LOC
- Have clear boundaries and deliverables
- Be independently testable
- Not leave the codebase in a broken state if stopped mid-plan
- Enable parallel work where possible
- If a phase exceeds these bounds, split it

**Complexity scale:**
| Size | Files Changed | LOC Changed | Example |
|------|---------------|-------------|---------|
| S | 1-3 files | <100 LOC | Config change, small fix, single file edit |
| M | 3-8 files | 100-500 LOC | Feature with tests, API endpoint, refactoring |
| L | 8-15 files | 500-1500 LOC | Complex feature, major refactoring, integration |

If a phase would be XL (15+ files or 1500+ LOC), split into sub-phases (e.g., Phase 3a, 3b).

**Target:** S-M per phase (max L). Minimum 2 files per phase to avoid trivial phases.

### Phase 4: Save and Report

1. Save RECOMMENDATIONS.md to the repository root
2. Save IMPLEMENTATION_PLAN.md to the repository root
3. Report a summary to the user including:
   - Total recommendations by category and priority
   - Number of phases in the implementation plan
   - Top 3 highest-impact recommendations
   - Suggested starting point

## Execution Guidelines

- **Be thorough**: This analysis informs significant work—miss nothing important
- **Be specific**: Vague recommendations waste time; include file paths, concrete approaches
- **Be realistic**: Estimate effort honestly; overrunning phases causes problems
- **Be practical**: Prioritize impact over elegance; ship value to users
- **Consider context**: Factor in the project's maturity, goals, and constraints
- **Enable parallelism**: Structure phases so multiple streams can work simultaneously when possible
- **Preserve stability**: Each phase should leave the codebase in a working state

## Performance

**Typical Duration:**

| Codebase Size | Expected Time |
|---------------|---------------|
| Small (< 50 files) | 1-2 minutes |
| Medium (50-200 files) | 3-5 minutes |
| Large (200-500 files) | 5-10 minutes |
| Very Large (500+ files) | 10-20 minutes |

**Factors Affecting Performance:**
- **File count**: More files = longer analysis
- **Code complexity**: Complex interdependencies slow pattern detection
- **Language diversity**: Multiple languages require broader analysis
- **Documentation depth**: Comprehensive recommendations take longer to formulate

**Signs of Abnormal Behavior:**
- No output activity after 5 minutes
- Repeated file reading without progress
- Error messages about file access

**If the command seems stuck:**
1. Check for output activity (phase progress indicators)
2. Wait at least 10 minutes for large codebases
3. If no activity, interrupt and try `/review-arch` for a quicker analysis
4. Consider breaking into smaller scope (specific directories)

---

## Example Usage

```yaml
User: /plan-improvements

Claude: [Performs deep analysis of the codebase]

I've completed the improvement analysis for claude-marketplace.

**RECOMMENDATIONS.md created** with 23 recommendations across 5 categories:
- Usability: 6 (2 Critical, 2 High, 2 Medium)
- Output Quality: 4 (1 High, 3 Medium)
- Architecture: 5 (1 Critical, 2 High, 2 Medium)
- Developer Experience: 4 (2 High, 2 Low)
- New Capabilities: 4 (1 High, 2 Medium, 1 Low)

**IMPLEMENTATION_PLAN.md created** with 4 phases:
- Phase 1: Foundation (M, ~8 files, ~400 LOC) - Critical fixes and quick wins
- Phase 2: Quality (M, ~6 files, ~300 LOC) - Output improvements
- Phase 3: Architecture (L, ~12 files, ~800 LOC) - Structural refactoring
- Phase 4: Features (M, ~5 files, ~350 LOC) - New capabilities

**Top 3 Highest-Impact Recommendations:**
1. [A1] Standardize command frontmatter validation
2. [U2] Add interactive parameter prompting
3. [Q1] Implement output template system

**Suggested Starting Point:** Phase 1, Item 1.1 - addresses critical stability issue

Files saved:
- RECOMMENDATIONS.md
- IMPLEMENTATION_PLAN.md
```
